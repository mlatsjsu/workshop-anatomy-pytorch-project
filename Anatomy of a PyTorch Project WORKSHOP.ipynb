{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and examine our data\n",
    "Let's see what's in our data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"!ls\" command to list your directory contents. \n",
    "# The preceding exclamation mark tells Jupyter to run a bash command instead of Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Image class from PIL, the Python Image Library\n",
    "\n",
    "\n",
    "# open an image file of choice\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instantiate Dataset object\n",
    "\n",
    "**Purpose:** index and load the image files we want to use for our dataset, assign numeric labels to each class.\n",
    "\n",
    "We can either define a custom _Dataset_ class, or import a prebuilt _Dataset_ from the `torchvision` package. Because this is our first tutorial, let's use a prebuilt one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the <a href=\"https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder\">docs</a>, an ImageFolder Dataset helps load data arranged like this:\n",
    "```\n",
    "root/dog/xxx.png\n",
    "root/dog/xxy.png\n",
    "root/dog/xxz.png\n",
    "\n",
    "root/cat/123.png\n",
    "root/cat/nsdf3.png\n",
    "root/cat/asd932_.png\n",
    "```\n",
    "\n",
    "Here is the class signature. We at least need a **root directory**, but we should also pass in a **transform**.\n",
    "\n",
    "`torchvision.datasets.ImageFolder(root, transform=None, target_transform=None, loader=<function default_loader>, is_valid_file=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ImageFolder from torchvision.datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our transform will do the following:\n",
    "<img src=\"media/transform.jpg\" width=600/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transforms from torchvision\n",
    "\n",
    "# Declare transforms to (1) resize images (2) turn PIL Images into PyTorch Tensors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate an ImageFolder object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Dataset object is indexable, just like an array. Try accessing the 0th index, what gets returned?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem:** this basic iterator only loads one image at a time. But the power of a GPU comes from running multiple calculations in _parallel_. How can we load whole batches of images at once?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Declare DataLoader and data transforms\n",
    "\n",
    "**Purpose:** load data in the desired batch size, with shuffling, using multiple CPU threads for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the DataLoader class from torch.utils.data\n",
    "\n",
    "\n",
    "# instantiate a DataLoader object, pass in our instantiated Dataset object. Try examining its attributes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's in our dataloader?\n",
    "\n",
    "\n",
    "# check the shape of our data! notice how it prepends an extra batch dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. MODEL (Neural Network)\n",
    "\n",
    "**Purpose:** define our neural network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either define a custom architecture that extends _nn.Module_, or import a predefined architecture from `torchvision`. Because this is our first tutorial, let's again use torchvision.\n",
    "\n",
    "Here's a list of officially available models: https://pytorch.org/docs/stable/torchvision/models.html\n",
    "\n",
    "(Even more unofficial implementations are available <a href=\"https://github.com/Cadene/pretrained-models.pytorch\">here</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models\n",
    "\n",
    "# fetch an instance of AlexNet\n",
    "\n",
    "# examine the model parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram of AlexNet:\n",
    "<img src=\"media/alexnet.png\" width=500/>\n",
    "\n",
    "The output layer represents the number of classes. The index with the highest activation is the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check, pass an image through our network\n",
    "\n",
    "\n",
    "# what's the shape of the output?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this default architecture is for 1000 classes, not 2 classes for our problem. Let's add a final layer at the end. Notice how the architecture parameters ends with \"classifier?\" We'll modify that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn\n",
    "\n",
    "# overwrite the \"classifier\" to add a Linear 1000->2 layer at the end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick test, pass an image through our network. output should now be size 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. LOSS \n",
    "(a.k.a. cost or error function)\n",
    "\n",
    "**Purpose:** calculate how wrong the neural network's predictions are.\n",
    "\n",
    "Why do we need to choose a loss? Because there are multiple ways to define what error means, e.g. L1 error, L2 error. Let's use [CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#crossentropyloss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate CrossEntropyLoss object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a quick test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. OPTIMIZER\n",
    "\n",
    "**Purpose:** decide how the model should respond to error.\n",
    "\n",
    "See official available optimizers [here](https://pytorch.org/docs/stable/optim.html).\n",
    "\n",
    "Examples of different optimization strategies on varying error surfaces.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td> <img src=\"media/optimizer_1.gif\" height=\"275\" /> </td>\n",
    "    <td> <img src=\"media/optimizer_2.gif\" height=\"275\" /> </td>\n",
    "    <td> <img src=\"media/optimizer_3.gif\" height=\"275\" /> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim\n",
    "\n",
    "# instantiate an optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. TRAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a device object for GPU usage\n",
    "\n",
    "\n",
    "# move our model to the device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for n epochs. an epoch is a full iteration through our dataset\n",
    "\n",
    "\n",
    "# create something to track of accuracy over time\n",
    "\n",
    "\n",
    "# loop over epochs\n",
    "\n",
    "    \n",
    "    # track our accuracy\n",
    "\n",
    "    \n",
    "    # loop over our data loader\n",
    "\n",
    "\n",
    "        \n",
    "        # pass data through model\n",
    "\n",
    "        # calculate the loss\n",
    "\n",
    "        \n",
    "        # Use our optimizer to update the network\n",
    "        # 1: zero_grad our optimizer\n",
    "\n",
    "        # 2: run a backward pass\n",
    "\n",
    "        # 3: make a step\n",
    "\n",
    "        \n",
    "        # calculate predictions so we can track accuracy\n",
    "        \n",
    "        \n",
    "    \n",
    "    # calculate the accuracy by dividing correct by length of the dataset\n",
    "    \n",
    "    \n",
    "    # append accuracy to our list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a simple line plot using pandas, ylim between 0 and 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. VISUALIZE RESULTS\n",
    "\n",
    "**Consider:** How accurate was your model? How confident were its predictions? Does it make clear-cut decisions?\n",
    "\n",
    "Feel free to use the below function to visualize results. I won't go through it because its details is not part of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # graphical library, to plot images\n",
    "# special Jupyter notebook command to show plots inline instead of in a new window\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from math import floor\n",
    "\n",
    "def visualize_results(data_root, model, transforms):\n",
    "    set_eval = False\n",
    "    if model.training:\n",
    "        set_eval=True\n",
    "        model.eval()\n",
    "    \n",
    "    val_dataset = ImageFolder(data_root, transforms)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_dataset))\n",
    "    data, labels = next(iter(val_loader))\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "    outputs = my_net(data)\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    num_correct = torch.sum(preds==labels.data).item()\n",
    "    pred_probs = torch.nn.functional.softmax(outputs, dim=-1).cpu().data.numpy()\n",
    "    \n",
    "\n",
    "    print(\"VALIDATION ACCURACY:\", num_correct / len(val_dataset))\n",
    "\n",
    "    # show the probabilities for each picture\n",
    "    fig, axs = plt.subplots(6, 5, figsize=(20, 20))\n",
    "    images = [Image.open(img_path) for img_path in list(zip(*val_dataset.samples))[0]]\n",
    "    for i, img in enumerate(images):\n",
    "        ax = axs[floor(i/5)][i % 5]\n",
    "        ax.axis('off')\n",
    "        ax.set_title(\"{:.0f}% Chi, {:.0f}% Muff\".format(100*pred_probs[i,0], 100*pred_probs[i,1]), fontsize=18)\n",
    "        ax.imshow(img)\n",
    "    \n",
    "    if set_eval:\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function visualize_results()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You've successfully trained a neural network!\n",
    "\n",
    "# Can You Do Better?\n",
    "\n",
    "Now that we've shown you how to train a neural network, can you improve the validation accuracy by tweaking the parameters? **We challenge you to reach 100% accuracy!** (hint, it's not too hard).\n",
    "\n",
    "Some parameters to play with:\n",
    "- Number of epochs\n",
    "- The model type\n",
    "- The learning rate \"lr\" parameter in the optimizer\n",
    "- The type of optimizer (https://pytorch.org/docs/stable/optim.html)\n",
    "- Number of layers and layer dimensions\n",
    "- Image size\n",
    "- Data augmentation transforms (https://pytorch.org/docs/stable/torchvision/transforms.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
